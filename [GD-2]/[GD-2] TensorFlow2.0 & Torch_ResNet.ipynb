{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "clean-summary",
   "metadata": {},
   "source": [
    "### residual_block.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "little-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        if stride != 1:\n",
    "            self.downsample = tf.keras.Sequential()\n",
    "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                       kernel_size=(1, 1),\n",
    "                                                       strides=stride))\n",
    "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.downsample(inputs)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class BottleNeck(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=1,\n",
    "                                            padding='same')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=stride,\n",
    "                                            padding='same')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=1,\n",
    "                                            padding='same')\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.downsample = tf.keras.Sequential()\n",
    "        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
    "                                                   kernel_size=(1, 1),\n",
    "                                                   strides=stride))\n",
    "        self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.downsample(inputs)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training=training)\n",
    "\n",
    "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
    "    res_block = tf.keras.Sequential()\n",
    "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        res_block.add(BasicBlock(filter_num, stride=1))\n",
    "\n",
    "    return res_block\n",
    "\n",
    "\n",
    "def make_bottleneck_layer(filter_num, blocks, stride=1):\n",
    "    res_block = tf.keras.Sequential()\n",
    "    res_block.add(BottleNeck(filter_num, stride=stride))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        res_block.add(BottleNeck(filter_num, stride=1))\n",
    "\n",
    "    return res_block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-removal",
   "metadata": {},
   "source": [
    "### resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaptive-sculpture",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5af90ebd10ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_block\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_basic_block_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_bottleneck_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from config import NUM_CLASSES\n",
    "from models.residual_block import make_basic_block_layer, make_bottleneck_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "familiar-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetTypeI(tf.keras.Model):\n",
    "    def __init__(self, layer_params):\n",
    "        super(ResNetTypeI, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                            kernel_size=(7, 7),\n",
    "                                            strides=2,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
    "                                               strides=2,\n",
    "                                               padding=\"same\")\n",
    "\n",
    "        self.layer1 = make_basic_block_layer(filter_num=64,\n",
    "                                             blocks=layer_params[0])\n",
    "        self.layer2 = make_basic_block_layer(filter_num=128,\n",
    "                                             blocks=layer_params[1],\n",
    "                                             stride=2)\n",
    "        self.layer3 = make_basic_block_layer(filter_num=256,\n",
    "                                             blocks=layer_params[2],\n",
    "                                             stride=2)\n",
    "        self.layer4 = make_basic_block_layer(filter_num=512,\n",
    "                                             blocks=layer_params[3],\n",
    "                                             stride=2)\n",
    "\n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.layer1(x, training=training)\n",
    "        x = self.layer2(x, training=training)\n",
    "        x = self.layer3(x, training=training)\n",
    "        x = self.layer4(x, training=training)\n",
    "        x = self.avgpool(x)\n",
    "        output = self.fc(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class ResNetTypeII(tf.keras.Model):\n",
    "    def __init__(self, layer_params):\n",
    "        super(ResNetTypeII, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                            kernel_size=(7, 7),\n",
    "                                            strides=2,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
    "                                               strides=2,\n",
    "                                               padding=\"same\")\n",
    "\n",
    "        self.layer1 = make_bottleneck_layer(filter_num=64,\n",
    "                                            blocks=layer_params[0])\n",
    "        self.layer2 = make_bottleneck_layer(filter_num=128,\n",
    "                                            blocks=layer_params[1],\n",
    "                                            stride=2)\n",
    "        self.layer3 = make_bottleneck_layer(filter_num=256,\n",
    "                                            blocks=layer_params[2],\n",
    "                                            stride=2)\n",
    "        self.layer4 = make_bottleneck_layer(filter_num=512,\n",
    "                                            blocks=layer_params[3],\n",
    "                                            stride=2)\n",
    "\n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.layer1(x, training=training)\n",
    "        x = self.layer2(x, training=training)\n",
    "        x = self.layer3(x, training=training)\n",
    "        x = self.layer4(x, training=training)\n",
    "        x = self.avgpool(x)\n",
    "        output = self.fc(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def resnet_18():\n",
    "    return ResNetTypeI(layer_params=[2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def resnet_34():\n",
    "    return ResNetTypeI(layer_params=[3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def resnet_50():\n",
    "    return ResNetTypeII(layer_params=[3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def resnet_101():\n",
    "    return ResNetTypeII(layer_params=[3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def resnet_152():\n",
    "    return ResNetTypeII(layer_params=[3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-intention",
   "metadata": {},
   "source": [
    "### ResNet torch model.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spatial-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/KellerJordan/ResNet-PyTorch-CIFAR10/blob/master/model.py\n",
    "class IdentityPadding(nn.Module):\n",
    "\tdef __init__(self, in_channels, out_channels, stride):\n",
    "\t\tsuper(IdentityPadding, self).__init__()\n",
    "\t\t\n",
    "\t\tself.pooling = nn.MaxPool2d(1, stride=stride)\n",
    "\t\tself.add_channels = out_channels - in_channels\n",
    "    \n",
    "\tdef forward(self, x):\n",
    "\t\tout = F.pad(x, (0, 0, 0, 0, 0, self.add_channels))\n",
    "\t\tout = self.pooling(out)\n",
    "\t\treturn out\n",
    "\t\n",
    "\t\n",
    "class ResidualBlock(nn.Module):\n",
    "\tdef __init__(self, in_channels, out_channels, stride=1, down_sample=False):\n",
    "\t\tsuper(ResidualBlock, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "\t\t\t                   stride=stride, padding=1, bias=False) \n",
    "\t\tself.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\t\tself.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
    "\t\t\t                   stride=1, padding=1, bias=False) \n",
    "\t\tself.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\t\tself.stride = stride\n",
    "\t\t\n",
    "\t\tif down_sample:\n",
    "\t\t\tself.down_sample = IdentityPadding(in_channels, out_channels, stride)\n",
    "\t\telse:\n",
    "\t\t\tself.down_sample = None\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tshortcut = x\n",
    "\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.bn1(out)\n",
    "\t\tout = self.relu(out)\n",
    "\n",
    "\t\tout = self.conv2(out)\n",
    "\t\tout = self.bn2(out)\n",
    "\n",
    "\t\tif self.down_sample is not None:\n",
    "\t\t\tshortcut = self.down_sample(x)\n",
    "\n",
    "\t\tout += shortcut\n",
    "\t\tout = self.relu(out)\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\tdef __init__(self, num_layers, block, num_classes=10):\n",
    "\t\tsuper(ResNet, self).__init__()\n",
    "\t\tself.num_layers = num_layers\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, \n",
    "\t\t\t\t\t\t\t   stride=1, padding=1, bias=False)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(16)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\t\n",
    "\t\t# feature map size = 32x32x16\n",
    "\t\tself.layers_2n = self.get_layers(block, 16, 16, stride=1)\n",
    "\t\t# feature map size = 16x16x32\n",
    "\t\tself.layers_4n = self.get_layers(block, 16, 32, stride=2)\n",
    "\t\t# feature map size = 8x8x64\n",
    "\t\tself.layers_6n = self.get_layers(block, 32, 64, stride=2)\n",
    "\n",
    "\t\t# output layers\n",
    "\t\tself.avg_pool = nn.AvgPool2d(8, stride=1)\n",
    "\t\tself.fc_out = nn.Linear(64, num_classes)\n",
    "\t\t\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\t\tnn.init.kaiming_normal_(m.weight, mode='fan_out', \n",
    "\t\t\t\t\t                    nonlinearity='relu')\n",
    "\t\t\telif isinstance(m, nn.BatchNorm2d):\n",
    "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
    "\t\t\t\tnn.init.constant_(m.bias, 0)\n",
    "\t\n",
    "\tdef get_layers(self, block, in_channels, out_channels, stride):\n",
    "\t\tif stride == 2:\n",
    "\t\t\tdown_sample = True\n",
    "\t\telse:\n",
    "\t\t\tdown_sample = False\n",
    "\t\t\n",
    "\t\tlayers_list = nn.ModuleList(\n",
    "\t\t\t[block(in_channels, out_channels, stride, down_sample)])\n",
    "\t\t\t\n",
    "\t\tfor _ in range(self.num_layers - 1):\n",
    "\t\t\tlayers_list.append(block(out_channels, out_channels))\n",
    "\n",
    "\t\treturn nn.Sequential(*layers_list)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.bn1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\n",
    "\t\tx = self.layers_2n(x)\n",
    "\t\tx = self.layers_4n(x)\n",
    "\t\tx = self.layers_6n(x)\n",
    "\n",
    "\t\tx = self.avg_pool(x)\n",
    "\t\tx = x.view(x.size(0), -1)\n",
    "\t\tx = self.fc_out(x)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "def resnet():\n",
    "\tblock = ResidualBlock\n",
    "\t# total number of layers if 6n + 2. if n is 5 then the depth of network is 32.\n",
    "\tmodel = ResNet(5, block) \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wrong-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n=7, res_option='A', use_dropout=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.res_option = res_option\n",
    "        self.use_dropout = use_dropout\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.layers1 = self._make_layer(n, 16, 16, 1)\n",
    "        self.layers2 = self._make_layer(n, 32, 16, 2)\n",
    "        self.layers3 = self._make_layer(n, 64, 32, 2)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.linear = nn.Linear(64, 10)\n",
    "    \n",
    "    def _make_layer(self, layer_count, channels, channels_in, stride):\n",
    "        return nn.Sequential(\n",
    "            ResBlock(channels, channels_in, stride, res_option=self.res_option, use_dropout=self.use_dropout),\n",
    "            *[ResBlock(channels) for _ in range(layer_count-1)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.layers1(out)\n",
    "        out = self.layers2(out)\n",
    "        out = self.layers3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_filters, channels_in=None, stride=1, res_option='A', use_dropout=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        # uses 1x1 convolutions for downsampling\n",
    "        if not channels_in or channels_in == num_filters:\n",
    "            channels_in = num_filters\n",
    "            self.projection = None\n",
    "        else:\n",
    "            if res_option == 'A':\n",
    "                self.projection = IdentityPadding(num_filters, channels_in, stride)\n",
    "            elif res_option == 'B':\n",
    "                self.projection = ConvProjection(num_filters, channels_in, stride)\n",
    "            elif res_option == 'C':\n",
    "                self.projection = AvgPoolPadding(num_filters, channels_in, stride)\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.conv1 = nn.Conv2d(channels_in, num_filters, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_filters)\n",
    "        if self.use_dropout:\n",
    "            self.dropout = nn.Dropout(inplace=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.use_dropout:\n",
    "            out = self.dropout(out)\n",
    "        if self.projection:\n",
    "            residual = self.projection(x)\n",
    "        out += residual\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# various projection options to change number of filters in residual connection\n",
    "# option A from paper\n",
    "class IdentityPadding(nn.Module):\n",
    "    def __init__(self, num_filters, channels_in, stride):\n",
    "        super(IdentityPadding, self).__init__()\n",
    "        # with kernel_size=1, max pooling is equivalent to identity mapping with stride\n",
    "        self.identity = nn.MaxPool2d(1, stride=stride)\n",
    "        self.num_zeros = num_filters - channels_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (0, 0, 0, 0, 0, self.num_zeros))\n",
    "        out = self.identity(out)\n",
    "        return out\n",
    "\n",
    "# option B from paper\n",
    "class ConvProjection(nn.Module):\n",
    "\n",
    "    def __init__(self, num_filters, channels_in, stride):\n",
    "        super(ResA, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels_in, num_filters, kernel_size=1, stride=stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "# experimental option C\n",
    "class AvgPoolPadding(nn.Module):\n",
    "\n",
    "    def __init__(self, num_filters, channels_in, stride):\n",
    "        super(AvgPoolPadding, self).__init__()\n",
    "        self.identity = nn.AvgPool2d(stride, stride=stride)\n",
    "        self.num_zeros = num_filters - channels_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (0, 0, 0, 0, 0, self.num_zeros))\n",
    "        out = self.identity(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-nowhere",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
